{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow_TexGenerator_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPGY0KkceFIDNVCRlGidHaG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4aHK2CYygXom"},"source":["## Import TensorFlow and related functions"]},{"cell_type":"code","metadata":{"id":"2LmLTREBf5ng","executionInfo":{"status":"ok","timestamp":1626057382830,"user_tz":300,"elapsed":1580,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Other imports for processing data\n","import string\n","import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Bf5FVHfganK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626057386349,"user_tz":300,"elapsed":3524,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"c720a779-9069-4691-ecda-a06aaf25ee91"},"source":["!wget --no-check-certificate \\\n","    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n","    -O /tmp/songdata.csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-07-12 02:36:22--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n","Resolving drive.google.com (drive.google.com)... 74.125.142.113, 74.125.142.102, 74.125.142.100, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.142.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bot6voeth2jr09b4dc34k2iq00366kk2/1626057375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-07-12 02:36:25--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bot6voeth2jr09b4dc34k2iq00366kk2/1626057375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n","Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 108.177.98.132, 2607:f8b0:400e:c06::84\n","Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|108.177.98.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/csv]\n","Saving to: ‘/tmp/songdata.csv’\n","\n","/tmp/songdata.csv       [   <=>              ]  69.08M   147MB/s    in 0.5s    \n","\n","2021-07-12 02:36:26 (147 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nWbMN_19jfRT"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"id":"LRmPPJegovBe","executionInfo":{"status":"ok","timestamp":1626057386349,"user_tz":300,"elapsed":4,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["def tokenize_corpus(corpus, num_words=-1):\n","  # Fit a Tokenizer on the corpus\n","  if num_words > -1:\n","    tokenizer = Tokenizer(num_words=num_words)\n","  else:\n","    tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(corpus)\n","  return tokenizer\n","\n","def create_lyrics_corpus(dataset, field):\n","  # Remove all other punctuation\n","  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n","  # Make it lowercase\n","  dataset[field] = dataset[field].str.lower()\n","  # Make it one long string to split by line\n","  lyrics = dataset[field].str.cat()\n","  corpus = lyrics.split('\\n')\n","  # Remove any trailing whitespace\n","  for l in range(len(corpus)):\n","    corpus[l] = corpus[l].rstrip()\n","  # Remove any empty lines\n","  corpus = [l for l in corpus if l != '']\n","\n","  return corpus"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIGedF3XjHj4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626057387222,"user_tz":300,"elapsed":876,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"93340b76-aa95-4833-a83e-2568c76b7f83"},"source":["def tokenize_corpus(corpus, num_words=-1):\n","  # Fit a Tokenizer on the corpus\n","  if num_words > -1:\n","    tokenizer = Tokenizer(num_words=num_words)\n","  else:\n","    tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(corpus)\n","  return tokenizer\n","\n","# Read the dataset from csv - this time with 250 songs\n","number_songs=250\n","dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:number_songs]\n","# Create the corpus using the 'text' column containing lyrics\n","corpus = create_lyrics_corpus(dataset, 'text')\n","# Tokenize the corpus\n","tokenizer = tokenize_corpus(corpus, num_words=2000)\n","total_words = tokenizer.num_words\n","\n","# There should be a lot more words now\n","print(total_words)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"quoDmw_FkNBA"},"source":["### Create Sequences and Labels"]},{"cell_type":"code","metadata":{"id":"kkLAf3HmkPSo","executionInfo":{"status":"ok","timestamp":1626057387691,"user_tz":300,"elapsed":471,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tsequences.append(n_gram_sequence)\n","\n","# Pad sequences for equal input length \n","max_sequence_len = max([len(seq) for seq in sequences])\n","sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# Split sequences between the \"input\" sequence and \"output\" predicted word\n","input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n","# One-hot encode the labels\n","one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQULyB-UkUWP"},"source":["#Build the model"]},{"cell_type":"code","metadata":{"id":"7nHOp6uWlP_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626058540901,"user_tz":300,"elapsed":1153212,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"1a4ae1f3-048d-4a3c-a8f1-6fcc62b7a314"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(20)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1480/1480 [==============================] - 20s 8ms/step - loss: 5.9789 - accuracy: 0.0468\n","Epoch 2/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 5.6685 - accuracy: 0.0518\n","Epoch 3/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 5.4787 - accuracy: 0.0673\n","Epoch 4/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 5.3335 - accuracy: 0.0834\n","Epoch 5/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 5.1849 - accuracy: 0.1070\n","Epoch 6/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 5.0338 - accuracy: 0.1299\n","Epoch 7/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.9024 - accuracy: 0.1418\n","Epoch 8/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.7819 - accuracy: 0.1514\n","Epoch 9/100\n","1480/1480 [==============================] - 11s 7ms/step - loss: 4.6761 - accuracy: 0.1616\n","Epoch 10/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.5790 - accuracy: 0.1717\n","Epoch 11/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.4877 - accuracy: 0.1826\n","Epoch 12/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.4006 - accuracy: 0.1932\n","Epoch 13/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.3010 - accuracy: 0.2037\n","Epoch 14/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.1943 - accuracy: 0.2182\n","Epoch 15/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.0955 - accuracy: 0.2292\n","Epoch 16/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 4.0042 - accuracy: 0.2416\n","Epoch 17/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.9255 - accuracy: 0.2519\n","Epoch 18/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.8530 - accuracy: 0.2602\n","Epoch 19/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 3.7855 - accuracy: 0.2700\n","Epoch 20/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.7250 - accuracy: 0.2781\n","Epoch 21/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 3.6679 - accuracy: 0.2854\n","Epoch 22/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 3.6144 - accuracy: 0.2946\n","Epoch 23/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.5675 - accuracy: 0.3001\n","Epoch 24/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.5230 - accuracy: 0.3074\n","Epoch 25/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.4779 - accuracy: 0.3123\n","Epoch 26/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.4374 - accuracy: 0.3195\n","Epoch 27/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.3960 - accuracy: 0.3249\n","Epoch 28/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.3587 - accuracy: 0.3305\n","Epoch 29/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.3198 - accuracy: 0.3363\n","Epoch 30/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.2853 - accuracy: 0.3416\n","Epoch 31/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.2532 - accuracy: 0.3443\n","Epoch 32/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.2222 - accuracy: 0.3505\n","Epoch 33/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.1874 - accuracy: 0.3542\n","Epoch 34/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.1541 - accuracy: 0.3610\n","Epoch 35/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.1277 - accuracy: 0.3651\n","Epoch 36/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.1026 - accuracy: 0.3690\n","Epoch 37/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.0760 - accuracy: 0.3710\n","Epoch 38/100\n","1480/1480 [==============================] - 11s 7ms/step - loss: 3.0541 - accuracy: 0.3756\n","Epoch 39/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.0266 - accuracy: 0.3817\n","Epoch 40/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 3.0051 - accuracy: 0.3841\n","Epoch 41/100\n","1480/1480 [==============================] - 11s 7ms/step - loss: 2.9802 - accuracy: 0.3907\n","Epoch 42/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.9570 - accuracy: 0.3933\n","Epoch 43/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.9365 - accuracy: 0.3973\n","Epoch 44/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.9205 - accuracy: 0.3984\n","Epoch 45/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.8972 - accuracy: 0.4035\n","Epoch 46/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.8763 - accuracy: 0.4065\n","Epoch 47/100\n","1480/1480 [==============================] - 11s 7ms/step - loss: 2.8633 - accuracy: 0.4086\n","Epoch 48/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.8416 - accuracy: 0.4115\n","Epoch 49/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.8263 - accuracy: 0.4151\n","Epoch 50/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.8042 - accuracy: 0.4165\n","Epoch 51/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7914 - accuracy: 0.4208\n","Epoch 52/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7736 - accuracy: 0.4229\n","Epoch 53/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7653 - accuracy: 0.4233\n","Epoch 54/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7534 - accuracy: 0.4266\n","Epoch 55/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7312 - accuracy: 0.4314\n","Epoch 56/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.7207 - accuracy: 0.4297\n","Epoch 57/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.7013 - accuracy: 0.4350\n","Epoch 58/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.6899 - accuracy: 0.4358\n","Epoch 59/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.6782 - accuracy: 0.4387\n","Epoch 60/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.6742 - accuracy: 0.4391\n","Epoch 61/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.6444 - accuracy: 0.4457\n","Epoch 62/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.6398 - accuracy: 0.4451\n","Epoch 63/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.6245 - accuracy: 0.4480\n","Epoch 64/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.6136 - accuracy: 0.4498\n","Epoch 65/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5988 - accuracy: 0.4527\n","Epoch 66/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.5902 - accuracy: 0.4534\n","Epoch 67/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5755 - accuracy: 0.4552\n","Epoch 68/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5694 - accuracy: 0.4578\n","Epoch 69/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.5673 - accuracy: 0.4569\n","Epoch 70/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5508 - accuracy: 0.4611\n","Epoch 71/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.5317 - accuracy: 0.4635\n","Epoch 72/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.5290 - accuracy: 0.4648\n","Epoch 73/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5266 - accuracy: 0.4646\n","Epoch 74/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.5027 - accuracy: 0.4692\n","Epoch 75/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.4867 - accuracy: 0.4711\n","Epoch 76/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4779 - accuracy: 0.4731\n","Epoch 77/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.4784 - accuracy: 0.4726\n","Epoch 78/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4656 - accuracy: 0.4745\n","Epoch 79/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4578 - accuracy: 0.4777\n","Epoch 80/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.4507 - accuracy: 0.4778\n","Epoch 81/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4438 - accuracy: 0.4798\n","Epoch 82/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4524 - accuracy: 0.4765\n","Epoch 83/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.4212 - accuracy: 0.4844\n","Epoch 84/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4132 - accuracy: 0.4841\n","Epoch 85/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.4099 - accuracy: 0.4857\n","Epoch 86/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.4055 - accuracy: 0.4864\n","Epoch 87/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.3914 - accuracy: 0.4880\n","Epoch 88/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.3801 - accuracy: 0.4905\n","Epoch 89/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3798 - accuracy: 0.4902\n","Epoch 90/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3717 - accuracy: 0.4914\n","Epoch 91/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3592 - accuracy: 0.4954\n","Epoch 92/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3871 - accuracy: 0.4877\n","Epoch 93/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.3480 - accuracy: 0.4982\n","Epoch 94/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3440 - accuracy: 0.4948\n","Epoch 95/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3368 - accuracy: 0.4981\n","Epoch 96/100\n","1480/1480 [==============================] - 11s 8ms/step - loss: 2.3254 - accuracy: 0.5007\n","Epoch 97/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3209 - accuracy: 0.5007\n","Epoch 98/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3159 - accuracy: 0.5035\n","Epoch 99/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3154 - accuracy: 0.5018\n","Epoch 100/100\n","1480/1480 [==============================] - 12s 8ms/step - loss: 2.3127 - accuracy: 0.5025\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MgvIz20nlQcq"},"source":["### View the Training Graph"]},{"cell_type":"code","metadata":{"id":"rOqmmarvlSLh","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1626058541346,"user_tz":300,"elapsed":449,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"e934a0e6-c574-4ae4-b091-abb503f05d13"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ISLZZGlQlSxh"},"source":["### Generate better lyrics!\n","\n","This time around, we should be able to get a more interesting output with less repetition."]},{"cell_type":"code","metadata":{"id":"P96oVMk3lU7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626058544906,"user_tz":300,"elapsed":3563,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"7bf37eac-b49c-45c3-9ec3-9157fcfc2d72"},"source":["seed_text = \"im feeling chills\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["im feeling chills and know that you can be able on your sweet little money more no worries paper away it died you think was a boomaboomerang is helping park place fans promise thunder doll feeling sensation watched bars ship goin test to buy rockin head meets chat ahead part tropical tiger other minute tropical doctor doctor doctor doctor doctor doctor doctor doctor city i followed longer baby wont do honey i could do i do i do i do i do i do i do i have weave like to sing hardly gave unreal i am the tiger day when i cant\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"upgJKV8_oRU9"},"source":["### Varying the Possible Outputs\n","\n","In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n","\n","Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."]},{"cell_type":"code","metadata":{"id":"lZe9gaJeoGVP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626058544907,"user_tz":300,"elapsed":5,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"5560572a-fcac-468e-939c-236d60b56ea0"},"source":["# Test the method with just the first word after the seed text\n","seed_text = \"im feeling chills\"\n","next_words = 100\n","  \n","token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","predicted_probs = model.predict(token_list)[0]\n","predicted = np.random.choice([x for x in range(len(predicted_probs))], \n","                             p=predicted_probs)\n","# Running this cell multiple times should get you some variance in output\n","print(predicted)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ee7WKgRGrJy1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626058548228,"user_tz":300,"elapsed":3323,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"f5d73fb8-58d6-4764-e911-4aeb01c52e63"},"source":["# Use this process for the full output generation\n","seed_text = \"im feeling chills\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","  predicted_probs = model.predict(token_list)[0]\n","  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n","                               p=predicted_probs)\n","  output_word = \"\"\n","  for word, index in tokenizer.word_index.items():\n","    if index == predicted:\n","      output_word = word\n","      break\n","  seed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["im feeling chills on me the fire in the took and with you if you closed the nights i can get anymore there aint all ill leave me myself sure what i had a little feelings away from loving too find sidewalks melody baby enough up slowly just nothing life gimme the same doll cries hid travel bet yellow tail chasing teacher supernatural diamond image explain farm fireplace absentminded ad feeds share four played shut road temperature tropical loveland cherry sensible stream famous bars misery happiest message beams ad melt tropical promise kids joke restless famous doll restless restless farm cover class looked\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P5ocWSpFmdIh"},"source":["#Model with multiple LSTM\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"2T576EjPmfu-","executionInfo":{"status":"error","timestamp":1626059711025,"user_tz":300,"elapsed":49998,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"ec2de035-322e-4d28-db58-1ecbbdc7eb0c"},"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(30)))\n","model.add(Bidirectional(LSTM(30)))\n","model.add(Dense(total_words*2, activation='sigmoid'))\n","model.add(Dense(total_words, activation='softmax'))\n","\n","earlyStopping = EarlyStopping(patience=10)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#Total_words = 2000\n","#max_sequence_len = 20\n"],"execution_count":29,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-a5912f29c587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2600\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer bidirectional_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 60)"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"n6jN1Bz-pm71","executionInfo":{"status":"error","timestamp":1626059617722,"user_tz":300,"elapsed":467185,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"86a0f9ff-3168-4ce6-f43b-8ce9fa648534"},"source":["history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","1480/1480 [==============================] - 13s 8ms/step - loss: 6.1220 - accuracy: 0.0457\n","Epoch 2/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0241 - accuracy: 0.0469\n","Epoch 3/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0157 - accuracy: 0.0469\n","Epoch 4/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0101 - accuracy: 0.0469\n","Epoch 5/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0078 - accuracy: 0.0469\n","Epoch 6/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0066 - accuracy: 0.0469\n","Epoch 7/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0062 - accuracy: 0.0469\n","Epoch 8/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0053 - accuracy: 0.0469\n","Epoch 9/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0051 - accuracy: 0.0469\n","Epoch 10/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0046 - accuracy: 0.0469\n","Epoch 11/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0046 - accuracy: 0.0469\n","Epoch 12/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0044 - accuracy: 0.0469\n","Epoch 13/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0036 - accuracy: 0.0469\n","Epoch 14/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0037 - accuracy: 0.0469\n","Epoch 15/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0034 - accuracy: 0.0469\n","Epoch 16/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0025 - accuracy: 0.0469\n","Epoch 17/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0029 - accuracy: 0.0469\n","Epoch 18/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0021 - accuracy: 0.0469\n","Epoch 19/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0019 - accuracy: 0.0469\n","Epoch 20/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0007 - accuracy: 0.0469\n","Epoch 21/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0008 - accuracy: 0.0469\n","Epoch 22/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0007 - accuracy: 0.0469\n","Epoch 23/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0002 - accuracy: 0.0469\n","Epoch 24/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 6.0006 - accuracy: 0.0469\n","Epoch 25/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9995 - accuracy: 0.0469\n","Epoch 26/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9989 - accuracy: 0.0469\n","Epoch 27/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9988 - accuracy: 0.0469\n","Epoch 28/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9985 - accuracy: 0.0469\n","Epoch 29/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9985 - accuracy: 0.0469\n","Epoch 30/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9988 - accuracy: 0.0469\n","Epoch 31/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9984 - accuracy: 0.0469\n","Epoch 32/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9982 - accuracy: 0.0469\n","Epoch 33/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9979 - accuracy: 0.0469\n","Epoch 34/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9971 - accuracy: 0.0469\n","Epoch 35/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9968 - accuracy: 0.0469\n","Epoch 36/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9969 - accuracy: 0.0469\n","Epoch 37/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9967 - accuracy: 0.0469\n","Epoch 38/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9968 - accuracy: 0.0469\n","Epoch 39/200\n","1480/1480 [==============================] - 12s 8ms/step - loss: 5.9965 - accuracy: 0.0469\n","Epoch 40/200\n"," 144/1480 [=>............................] - ETA: 10s - loss: 5.9631 - accuracy: 0.0449"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-085a181849a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_VzIopsoASw","executionInfo":{"status":"ok","timestamp":1626058550425,"user_tz":300,"elapsed":3,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"59498ab9-37e1-4fbc-f63a-4ce89e87c543"},"source":["model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 19, 64)            128000    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 40)                13600     \n","_________________________________________________________________\n","dense (Dense)                (None, 2000)              82000     \n","=================================================================\n","Total params: 223,600\n","Trainable params: 223,600\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}