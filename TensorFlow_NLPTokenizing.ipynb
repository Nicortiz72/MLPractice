{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow_NLPTokenizing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJcqdVrNXZHfGORGmeaJUW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4mGaRDFcSamt"},"source":["## Import the Tokenizer"]},{"cell_type":"code","metadata":{"id":"EN1-FZodOuPl","executionInfo":{"status":"ok","timestamp":1625970080685,"user_tz":300,"elapsed":1796,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["# Import the Tokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMiq8BpWVVRa","executionInfo":{"status":"ok","timestamp":1625970080686,"user_tz":300,"elapsed":5,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["sentences = [\n","    'My favorite food is ice cream',\n","    'do you like ice cream too?',\n","    'My dog likes ice cream!',\n","    \"your favorite flavor of icecream is chocolate\",\n","    \"chocolate isn't good for dogs\",\n","    \"your dog, your cat, and your parrot prefer broccoli\"\n","]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wz845OtfRBCM"},"source":["## Tokenize the words\n","\n","The first step to preparing text to be used in a machine learning model is to tokenize the text, in other words, to generate numbers for the words."]},{"cell_type":"code","metadata":{"id":"ZHTK1DAlQ1zO","executionInfo":{"status":"ok","timestamp":1625970082941,"user_tz":300,"elapsed":233,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["# Optionally set the max number of words to tokenize.\n","# The out of vocabulary (OOV) token represents words that are not in the index.\n","# Call fit_on_text() on the tokenizer to generate unique numbers for each word\n","tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX4VvsLySC7Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625970084110,"user_tz":300,"elapsed":225,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"74ed2284-569c-4436-de8d-15eec6045034"},"source":["# Examine the word index\n","word_index = tokenizer.word_index\n","print(word_index)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JXKrGxsIVtLo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625970086572,"user_tz":300,"elapsed":4,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"e0022b29-07a8-4fce-d1ba-27228873f5cf"},"source":["# Get the number for a given word\n","print(word_index['favorite'])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kcN_yM8O1oSX"},"source":["# Create sequences for the sentences\n","\n","After you tokenize the words, the word index contains a unique number for each word. However, the numbers in the word index are not ordered. Words in a sentence have an order. So after tokenizing the words, the next step is to generate sequences for the sentences."]},{"cell_type":"code","metadata":{"id":"QlUL6Ybf1sso","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625970103876,"user_tz":300,"elapsed":234,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"ef8306a5-f181-45a8-e37e-a26cc508c34a"},"source":["sequences = tokenizer.texts_to_sequences(sentences)\n","print (sequences)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AswZPbuW8f-f"},"source":["# Sequence sentences that contain words that are not in the word index\n","\n","Let's take a look at what happens if the sentence being sequenced contains words that are not in the word index.\n","\n","The Out of Vocabluary (OOV) token is the first entry in the word index. You will see it shows up in the sequences in place of any word that is not in the word index."]},{"cell_type":"code","metadata":{"id":"Fir7qd6X8eZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625970123113,"user_tz":300,"elapsed":230,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"21c5320a-a2c0-4f83-dd07-6abba43bb46c"},"source":["sentences2 = [\"I like hot chocolate\", \"My dogs and my hedgehog like kibble but my squirrel prefers grapes and my chickens like ice cream, preferably vanilla\"]\n","\n","sequences2 = tokenizer.texts_to_sequences(sentences2)\n","print(sequences2)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[1, 13, 1, 9], [5, 22, 24, 5, 1, 13, 1, 1, 5, 1, 1, 1, 24, 5, 1, 13, 3, 4, 1, 1]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vaYq1s4VYnlJ"},"source":["#Padding sentences to force some length\n"]},{"cell_type":"code","metadata":{"id":"5g_DZzTdYrY6","executionInfo":{"status":"ok","timestamp":1625970360564,"user_tz":300,"elapsed":227,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlDd9R_HYsR1","executionInfo":{"status":"ok","timestamp":1625970411275,"user_tz":300,"elapsed":225,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}}},"source":["padded = pad_sequences(sequences, maxlen=10)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3t48hFkjY5Yl","executionInfo":{"status":"ok","timestamp":1625970425954,"user_tz":300,"elapsed":232,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"8dd4da0b-9cf4-4edf-e766-b1e3c077af5c"},"source":["print(padded)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[ 0  0  0  0  5  6 10  7  3  4]\n"," [ 0  0  0  0 11 12 13  3  4 14]\n"," [ 0  0  0  0  0  5  8 15  3  4]\n"," [ 0  0  0  2  6 16 17 18  7  9]\n"," [ 0  0  0  0  0  9 19 20 21 22]\n"," [ 0  2  8  2 23 24  2 25 26 27]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AELI319AY8yR","executionInfo":{"status":"ok","timestamp":1625970448740,"user_tz":300,"elapsed":230,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"3eaf922d-6b94-4706-d86e-f87bff201ac9"},"source":["# Put the padding at the end of the sequences\n","padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n","print(padded)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n"," [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n"," [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n"," [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n"," [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n"," [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSVemnhbZCMW","executionInfo":{"status":"ok","timestamp":1625970498232,"user_tz":300,"elapsed":213,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"1c5ebad2-c434-4ec9-8a93-76f0ba59bdfa"},"source":["padded = pad_sequences(sequences, maxlen=8, padding=\"post\")\n","print(padded)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[[ 5  6 10  7  3  4  0  0]\n"," [11 12 13  3  4 14  0  0]\n"," [ 5  8 15  3  4  0  0  0]\n"," [ 2  6 16 17 18  7  9  0]\n"," [ 9 19 20 21 22  0  0  0]\n"," [ 8  2 23 24  2 25 26 27]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dKiS_L4dZ2Yz","executionInfo":{"status":"ok","timestamp":1625970766627,"user_tz":300,"elapsed":216,"user":{"displayName":"Nicolas Ortiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBiLp_CAeqmMamA3sv8BA8BczH2PSxygar6hIZ=s64","userId":"13431450490527970573"}},"outputId":"8ba24591-15cd-406a-9a60-ee4a0d48c7f7"},"source":["text=[\"hola como estas hola bien y tu\"]\n","tokenizer = Tokenizer(num_words = 10, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(text)\n","word_index = tokenizer.word_index\n","print(word_index)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["{'<OOV>': 1, 'hola': 2, 'como': 3, 'estas': 4, 'bien': 5, 'y': 6, 'tu': 7}\n"],"name":"stdout"}]}]}